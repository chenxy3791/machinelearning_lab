{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454d3709",
   "metadata": {},
   "source": [
    "# 1. 前言\n",
    "\n",
    "\n",
    "梯度提升机是集成学习中Boosting这一流派（其它集成学习方法还有bagging、stacking等）的一种方法，boosting流派中另外一种得到广泛应用的是自适应提升法（Adaptive Boost，简称Adaboost）。\n",
    "\n",
    "XGBoost( eXtreme Gradient Boosting：极限梯度提升)是基于决策树的集成机器学习算法，它以梯度提升（Gradient Boost）为框架，由GBDT发展而来。它的主要目标是提升模型运行的速度和有效性(efficiency)。同样是利用加法模型与前向分步算法实现学习的优化过程，但与GBDT是有区别的，主要包括以下几点：\n",
    "\n",
    "(1) 目标函数：XGBoost的损失函数添加了正则化项，使用正则用以控制模型的复杂度，正则项里包含了树的叶子节点个数、每个叶子节点权重（叶结点的socre值）的平方和。\n",
    "\n",
    "(2) 优化方法：GBDT在优化时只使用了一阶导数信息，XGBoost在优化时使用了一、二阶导数信息。\n",
    "\n",
    "(3) 缺失值处理：XBGoost对缺失值进行了处理，通过学习模型自动选择最优的缺失值默认切分方向。\n",
    "\n",
    "(4) 防止过拟合: XGBoost除了增加了正则项来防止过拟合,还支持行列采样的方式来防止过拟合。\n",
    "\n",
    "结果：它可以在最短时间内用更少的计算资源得到更好的结果。\n",
    "\n",
    "XGBoost被大量运用于竞赛中，比如Kaggle竞赛，在Kaggle2015年公布的29个获胜者中有17个使用了XGBoost，同样在KDDCup2015的竞赛中XGBoost也被大量使用。\n",
    "\n",
    "\n",
    "本文不涉及更深的理论介绍（感兴趣者可以去读原论文, Ref3提供了一个不错的解读），仅限于简要介绍如何构建你的第一个XGboost应用模型。\n",
    "\n",
    "\n",
    "## 1.1 安装或更新\n",
    "\n",
    "要使用XGboost，当然首先要安装XGboost(for use in Python)。如下一键式命令即可。\n",
    "\n",
    "conda/pip install xgboost\n",
    "\n",
    "或者如你是要更新的话：\n",
    "\n",
    "conda update xgboost\n",
    "\n",
    "or\n",
    "\n",
    "pip install -upgrade xgboost\n",
    "\n",
    "XGBoost\n",
    "\n",
    "XGBoost采用了scikit-learn中通用的封装方式，其使用方法和使用scikit-learn的内置模型是一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49c733",
   "metadata": {},
   "source": [
    "# 2. 第一个例子: Predict Onset of Diabetes\n",
    "\n",
    "在这个例子中，我们使用Pima Indians onset of diabetes dataset，该数据集(csv文件)可以从以下连接下载：(https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv),相应的说明文件：https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\n",
    "\n",
    "该数据集描述的是患者所接收的医疗记录，其标签则表示是否患有糖尿病的诊断结果。\n",
    "该数据集包含8个特征(all numeric-valued)，如下所示：\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "标签为二进制值{0,1}，表示是否患有糖尿病。\n",
    "   9. Class variable (0 or 1)\n",
    "\n",
    "从说明文件“pima-indians-diabetes.names.txt”或者UCI Machine Learning Repository website可以获得更加详细的信息。\n",
    "这个数据集由于其各特征都是数值(numberic)类型，且是一个简单的二分类问题，但是由于它过于简单而且数据集也比较小，所以，不一定是XGboost能够发挥优势的地方。\n",
    "\n",
    "## 2.1 加载数据\n",
    "\n",
    "以下用两种方法加载读入csv文件中的数据，一是pandas.read_csv，一是numpy.loadtxt()。两种方法输出的数据格式不一样，前者是Pandas DataFrame，后者是numpy ndarray，两者都可以。后续的fit()等函数对于两者都支持。Pandas读入生成的DataFrame的视觉效果更好一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d50bd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file C:\\Users\\chenxy\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file C:\\Users\\chenxy\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file C:\\Users\\chenxy\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file C:\\Users\\chenxy\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file C:\\Users\\chenxy\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file C:\\Users\\chenxy\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72b14c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "0     6  148  72  35    0  33.6  0.627  50  1\n",
       "1     1   85  66  29    0  26.6  0.351  31  0\n",
       "2     8  183  64   0    0  23.3  0.672  32  1\n",
       "3     1   89  66  23   94  28.1  0.167  21  0\n",
       "4     0  137  40  35  168  43.1  2.288  33  1\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "763  10  101  76  48  180  32.9  0.171  63  0\n",
       "764   2  122  70  27    0  36.8  0.340  27  0\n",
       "765   5  121  72  23  112  26.2  0.245  30  0\n",
       "766   1  126  60   0    0  30.1  0.349  47  1\n",
       "767   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data with Pandas\n",
    "df = pd.read_csv('pima-indians-diabetes.csv',header=None) # There is no header row in this csv file.\n",
    "# X = df[[0,1,2,3,4,5,6,7]]\n",
    "X_df = df.drop(columns=[8],axis=1) # Throw the column#8 to form train samples. The column#8 is label\n",
    "Y_df  = df[8]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc32c4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data with Numpy\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X_np = dataset[:,0:8]\n",
    "Y_np = dataset[:,8]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76ac0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X,Y = X_df, Y_df # Both are OK!\n",
    "X,Y = X_np, Y_np\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4a3e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b274d51",
   "metadata": {},
   "source": [
    "## 2.2 模型训练\n",
    "\n",
    "XGBoost提供了一个wrapper class，使得其中的模型可以以scikit-learn框架中的分类或者回归模型同样的方式使用。这也意味着XGBoost和scikit-learn库可以无缝结合使用。\n",
    "\n",
    "XGBoost中的分类模型为XGBClassifier，回归模型为XGBRegressor.本节我们用前者进行分类实验。XGBClassifier有很多参数可以使用，但是作为第一个例子我们尽量使用缺省的参数组合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a284a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:20:59] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=1,use_label_encoder=False) # 如果不指定use_label_encoder=False的话会导致警告\n",
    "model.fit(X_train, y_train)\n",
    "print(model) # 打印模型信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5df724",
   "metadata": {},
   "source": [
    "## 2.3 预测和评估\n",
    "\n",
    "可以用model.score()直接给出该模型分别在训练集和测试集上的预测准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5975f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over train set:  1.0\n",
      "Accuracy over test set:  0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy over train set: ', model.score(X_train, y_train))\n",
    "print('Accuracy over test set: ', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038b621",
   "metadata": {},
   "source": [
    "如果想知道针对每个样本的预测结果，则可以使用model.predict()函数。当然也可以使用model.predict_proba()函数得出针对每个样本的软预测结果，即概率性的预测结果，其中包含了预测结果的置信度信息。基于model.predict()调用结果，再调用accuracy_score也同样可以得到accuracy结果，model.score()相当于连续调用model.predict()和accuracy_score()但是没有输出中间的预测结果而已！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7935d8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0\n",
      " 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0\n",
      " 1 0 0 0 0 0]\n",
      "[[0.9896546  0.01034541]\n",
      " [0.00632519 0.9936748 ]\n",
      " [0.50282574 0.49717423]\n",
      " [0.9918761  0.00812385]\n",
      " [0.14539629 0.8546037 ]]\n",
      "Accuracy: 74.03%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_pred_proba = model.predict_proba(X_test)\n",
    "test_pred = model.predict(X_test)\n",
    "print(test_pred)\n",
    "print(test_pred_proba[:5,:])\n",
    "\n",
    "accuracy = accuracy_score(y_test, test_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707252b1",
   "metadata": {},
   "source": [
    "如上所示，软预测结果提供了一些额外的信息。比如说第3个样本，[0.50282574 0.49717423]，这意味着模型对这个样本的class#0和class#1的预测概率几乎相当，这说明本模型对于这个样本没有什么可说瞎蒙了一个而已。很可能在不同随机种子条件下进行训练得到的预测结果就不相同的。\n",
    "\n",
    "以下把左右代码串在一起构成一个完整pipeline。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5c5fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:21:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy over train set:  1.0\n",
      "Accuracy over test set:  0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data with Pandas\n",
    "df = pd.read_csv('pima-indians-diabetes.csv',header=None) # There is no header row in this csv file.\n",
    "# X = df[[0,1,2,3,4,5,6,7]]\n",
    "X = df.drop(columns=[8],axis=1) # Throw the column#8 to form train samples. The column#8 is label\n",
    "Y = df[8]\n",
    "\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = xgb.XGBClassifier(random_state=1,use_label_encoder=False)\n",
    "model.fit(X_train, y_train)\n",
    "print('Accuracy over train set: ', model.score(X_train, y_train))\n",
    "print('Accuracy over test set: ', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebb6f9",
   "metadata": {},
   "source": [
    "## 3 过拟合\n",
    "\n",
    "从以上结果来看，在训练集上达到了惊人的100%的预测准确度，而在测试集上只有74%，这个是明显的过拟合了。如何解决过拟合问题呢？\n",
    "\n",
    "过拟合与模型复杂度相关联，要想解消过拟合问题就必须降低模型复杂度。一般来说，梯度提升方法有以下三个参数与模型复杂度相关联：\n",
    "\n",
    "第一个是树的最大深度max_depth，树的深度越大意味着模型复杂度越高，其计算复杂度（内存需求、计算负荷）也更高。所以减小树的深度有利于解消过拟合问题。\n",
    "\n",
    "第二个是学习率learning_rate，用于控制每棵树纠正前一棵树的错误的强度。较高的学习率意味着每棵树都可以做出较强的修正，这样模型更加复杂。反过来说，降低学习率有助于降低模型复杂度并减轻过拟合问题。以下我们两种方法都试一试看。\n",
    "\n",
    "第三个是树的个数，由n_estimators指定。更多的树意味着更高的模型复杂度，因为模型有更多的机会纠正训练集上的错误。\n",
    "\n",
    "## 3.1 降低学习率\n",
    "\n",
    "XGBoost的缺省的学习率是0.1，以下我们将学习率将到0.01，训练集上的准确度降维90%，测试集上的准确度提高了2.5个百分点。过拟合现象有一定程度的解消，但是仍然比较严重。如果降到0.05的话，训练集和测试集上的准确度分为变为{88%, 78%}。进一步降低学习率变化不大，看来降低学习率不能完全解决过拟合的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e31d23ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:21:00] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy over train set:  0.8957654723127035\n",
      "Accuracy over test set:  0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=1,learning_rate=0.01,use_label_encoder=False)\n",
    "model.fit(X_train, y_train)\n",
    "print('Accuracy over train set: ', model.score(X_train, y_train))\n",
    "print('Accuracy over test set: ', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c10134",
   "metadata": {},
   "source": [
    "## 3.2 减小树的深度\n",
    "\n",
    "XGBoost的缺省的max_depth为6，以下我们在将学习率固定为0.01的条件下，降低该参数值看看会发生什么。\n",
    "\n",
    "learning_rate  max_depth  train_accuracy   test_accuracy\n",
    "\n",
    " 0.01       6       89.5%         76.6%\n",
    " \n",
    " 0.01       3       78.8%         77.6%\n",
    " \n",
    " 0.01       1       75.0%         74.6%\n",
    " \n",
    "\n",
    "看上去减小max_depth不是很有效，虽然max_depth=3在测试集上比max_depth=6要稍微好一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4732f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:08] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy over train set:  0.750814332247557\n",
      "Accuracy over test set:  0.7467532467532467\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=1,learning_rate=0.01,max_depth=1, use_label_encoder=False)\n",
    "model.fit(X_train, y_train)\n",
    "print('Accuracy over train set: ', model.score(X_train, y_train))\n",
    "print('Accuracy over test set: ', model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10b726",
   "metadata": {},
   "source": [
    "## 3.3 减小树的个数\n",
    "\n",
    "XGBoost的缺省的n_estimators为100，以下我们在将学习率固定为0.01，max_depth=3的条件下，降低该参数值看看会发生什么。\n",
    "\n",
    "n_estimators learning_rate  max_depth  train_accuracy   test_accuracy \n",
    "\n",
    "100       0.01       3       78.8%         77.6%\n",
    "\n",
    "80        0.01       3       78.1%         77.9% \n",
    "\n",
    "60        0.01       3       77.8%         77.9% \n",
    " \n",
    "如上所示，将树的个数降为80时，训练集和测试集上的准确度基本持平了，这个意味着已经很难再得到进一步的改进了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95684b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:23] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy over train set:  0.7785016286644951\n",
      "Accuracy over test set:  0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=1,learning_rate=0.01,max_depth=3,n_estimators=60,use_label_encoder=False)\n",
    "model.fit(X_train, y_train)\n",
    "print('Accuracy over train set: ', model.score(X_train, y_train))\n",
    "print('Accuracy over test set: ', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51858275",
   "metadata": {},
   "source": [
    "# 4. 归一化有好处吗？\n",
    "\n",
    "一般来说基于树的模型对于数据的缩放都不敏感，因此数据不需要进行归一化（包括均值归一化和方差归一化）。以下我们也通过实验来确定一下XGBoost分类器模型对于数据归一化是否敏感。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68243033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,) -8.789265611615822e-17 1.000000000000002\n",
      "[12:24:42] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy over train set:  0.7947882736156352\n",
      "Accuracy over test set:  0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 用numpy.loadtxt读取对于做归一化处理更方便\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# normalization of each feature\n",
    "X = (X - np.mean(X,axis=0))/np.std(X,axis=0)\n",
    "feature0 = X[:,0]\n",
    "print(feature0.shape, np.mean(feature0), np.std(feature0))\n",
    "\n",
    "# split data into train and test sets\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "\n",
    "model = xgb.XGBClassifier(random_state=1,learning_rate=0.01,max_depth=3,n_estimators=80,use_label_encoder=False)\n",
    "model.fit(X_train, y_train)\n",
    "print('Accuracy over train set: ', model.score(X_train, y_train))\n",
    "print('Accuracy over test set: ', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ed63f",
   "metadata": {},
   "source": [
    "# 5. 与其它模型的对比\n",
    "\n",
    "作为对比，以下我们也用GradientBoostingClassifier和KNeighborsClassifier基于同样的数据进行实验，看看相互之间的性能对比情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c11d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over train set:  0.7638436482084691\n",
      "Accuracy over test set:  0.7207792207792207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20d31fc79a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=1, learning_rate=0.01, max_depth=3, n_estimators=80)\n",
    "gbrt.fit(X_train,y_train)\n",
    "print('Accuracy over train set: ', gbrt.score(X_train, y_train))\n",
    "print('Accuracy over test set: ', gbrt.score(X_test,y_test))\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    " \n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bda4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# normalization of each feature\n",
    "X = (X - np.mean(X,axis=0))/np.std(X,axis=0)\n",
    "feature0 = X[:,0]\n",
    "print(feature0.shape, np.mean(feature0), np.std(feature0))\n",
    "\n",
    "# split data into train and test sets\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    " \n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae8f20",
   "metadata": {},
   "source": [
    "You can learn more about the defaults for the XGBClassifier and XGBRegressor classes in the XGBoost Python scikit-learn API.\n",
    "\n",
    "You can learn more about the meaning of each parameter and how to configure them on the XGBoost parameters page.\n",
    "\n",
    "We are now ready to use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6dd5c",
   "metadata": {},
   "source": [
    "结论是：训练数据的归一化对于XGboost在这个数据集上的表现没有什么影响。\n",
    "\n",
    "作为对比，我们还要看看，别的一些方法在这个数据集上的表现。当然，这个数据由于比较小，问题也比较简单，不一定是XGboost能够发挥优势的地方。所以如果看到XGboost没有比其它更简单的算法体现出什么优势也不必感到有什么惊讶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "     max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9c860",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "1. https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "\n",
    "2. https://www.section.io/engineering-education/machine-learning-with-xgboost-and-scikit-learn/\n",
    "\n",
    "3. https://zhuanlan.zhihu.com/p/75217528\n",
    "\n",
    "4. Andreas C.Muller, Sarah Guido, Introduction to Machine Leanring with Python（《Python机器学习基础教程》）\n",
    "\n",
    "5. https://zhuanlan.zhihu.com/p/448086099\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6b116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f6043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
